{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\M-SI\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similar words to 'motorcycle' (Skip-Gram): [('without', 0.9853965640068054), ('riding', 0.9846853017807007), ('being', 0.9825158715248108), ('program', 0.9818881154060364), ('dog', 0.9811667203903198), ('right', 0.9796724319458008), ('second', 0.9795583486557007), ('helmet', 0.9793109893798828), ('after', 0.9791327714920044), ('way', 0.9791204929351807)]\n",
            "Similar words to 'motorcycle' (CBOW): [('lock', 0.9916985630989075), ('image', 0.9916812777519226), ('machine', 0.9916216731071472), ('group', 0.9907560348510742), ('without', 0.9906614422798157), ('being', 0.9904513359069824), ('tank', 0.9882991909980774), ('line', 0.9882330894470215), ('rather', 0.9881882071495056), ('large', 0.9881352782249451)]\n"
          ]
        }
      ],
      "source": [
        "# Kerjakan latihan 1 pada cell berikut ini\n",
        "# Nomor 1 dan 2\n",
        "#Bangunlah word embedding dengan data 3 kategori lainnya dari data 20newsGroup\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "categories = ['rec.motorcycles', 'comp.os.ms-windows.misc', 'misc.forsale']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "documents = []\n",
        "for document in newsgroups_data.data:\n",
        "  # Preprocess the text: lowercase, tokenize\n",
        "  tokens = word_tokenize(document.lower())\n",
        "  documents.append(tokens)\n",
        "\n",
        "# Training menggunakan Skip-Gram\n",
        "skipgram_model = Word2Vec(documents, window=5, min_count=1, sg=1)\n",
        "skipgram_vectors = skipgram_model.wv\n",
        "\n",
        "# Training menggunakan CBOW\n",
        "cbow_model = Word2Vec(documents, window=5, min_count=1, sg=0)\n",
        "cbow_vectors = cbow_model.wv\n",
        "\n",
        "# Find similar words to \"motorcycle\" using Skip-Gram model\n",
        "similar_words = skipgram_vectors.most_similar(\"motorcycle\", topn=10)\n",
        "print(\"Similar words to 'motorcycle' (Skip-Gram):\", similar_words)\n",
        "\n",
        "# Find similar words to \"motorcycle\" using CBOW model\n",
        "similar_words = cbow_vectors.most_similar(\"motorcycle\", topn=10)\n",
        "print(\"Similar words to 'motorcycle' (CBOW):\", similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cGySaSuNYS1V"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A_7t5TbRHL5",
        "outputId": "f5810ed2-1167-46f3-fa7b-55d2b4185853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77\n",
            "121\n",
            "162\n",
            "186\n",
            "216\n",
            "done step 1\n",
            "done step 2\n",
            "done step 3\n",
            "done step 4\n",
            "done step 5\n"
          ]
        }
      ],
      "source": [
        "  # Kerjakan latihan 3 pada cell berikut ini\n",
        "# Kelompok O Hands on 2\n",
        "# Nama Anggota Kelompok : Calvin (003) & Zikra (007)\n",
        "# Create an empty list to store url link\n",
        "url_content_dict_1 = {}\n",
        "url_content_dict_2 = {}\n",
        "url_content_dict_3 = {}\n",
        "url_content_dict_4 = {}\n",
        "url_content_dict_5 = {}\n",
        "\n",
        "# get the url until the last page number of each url and add the category for each url\n",
        "# categories = [\"riba\", \"pembatal-pembatal-wudu\"]\n",
        "url = [\n",
        "    \"https://islamqa.info/id/categories/topics/67/pembatal-pembatal-wudu?page=\",\n",
        "    \"https://islamqa.info/id/categories/topics/147/riba?page=\",\n",
        "    \"https://islamqa.info/id/categories/topics/172/wakaf?page=\",\n",
        "    \"https://islamqa.info/id/categories/topics/148/jual-beli-yang-dilarang?page=\",\n",
        "    \"https://islamqa.info/id/categories/topics/156/harta-warisan-dan-pembagiannya\"\n",
        "        ]\n",
        "for i in range(1, 7):\n",
        "    url_content_dict_1[i] = requests.get(url[0] + str(i))\n",
        "for i in range(1, 4):\n",
        "    url_content_dict_2[i] = requests.get(url[1] + str(i))\n",
        "    url_content_dict_3[i] = requests.get(url[2] + str(i))\n",
        "for i in range(1, 3):\n",
        "    url_content_dict_4[i] = requests.get(url[3] + str(i))\n",
        "    url_content_dict_5[i] = requests.get(url[4] + str(i))\n",
        "\n",
        "# Create an empty list to store the links\n",
        "links_list = []\n",
        "\n",
        "# parse the content using BeautifulSoup\n",
        "for i in range(1, 7):\n",
        "    soup = BeautifulSoup(url_content_dict_1[i].content, \"html.parser\")\n",
        "    for link in soup.find_all(\"a\", class_=\"card post-card\"):\n",
        "        links_list.append(link.get(\"href\"))\n",
        "print(len(links_list))\n",
        "\n",
        "for i in range(1, 4):\n",
        "    soup = BeautifulSoup(url_content_dict_2[i].content, \"html.parser\")\n",
        "    for link in soup.find_all(\"a\", class_=\"card post-card\"):\n",
        "        links_list.append(link.get(\"href\"))\n",
        "print(len(links_list))\n",
        "\n",
        "for i in range(1, 4):\n",
        "    soup = BeautifulSoup(url_content_dict_3[i].content, \"html.parser\")\n",
        "    for link in soup.find_all(\"a\", class_=\"card post-card\"):\n",
        "        links_list.append(link.get(\"href\"))\n",
        "print(len(links_list))\n",
        "\n",
        "for i in range(1, 3):\n",
        "    soup = BeautifulSoup(url_content_dict_4[i].content, \"html.parser\")\n",
        "    for link in soup.find_all(\"a\", class_=\"card post-card\"):\n",
        "        links_list.append(link.get(\"href\"))\n",
        "print(len(links_list))\n",
        "\n",
        "for i in range(1, 3):\n",
        "    soup = BeautifulSoup(url_content_dict_5[i].content, \"html.parser\")\n",
        "    for link in soup.find_all(\"a\", class_=\"card post-card\"):\n",
        "        links_list.append(link.get(\"href\"))\n",
        "print(len(links_list))\n",
        "\n",
        "url_QnA_dict_1 = {}\n",
        "url_QnA_dict_2 = {}\n",
        "url_QnA_dict_3 = {}\n",
        "url_QnA_dict_4 = {}\n",
        "url_QnA_dict_5 = {}\n",
        "\n",
        "for i in range(1, 78):\n",
        "    url_QnA_dict_1[i] = requests.get(links_list[i])\n",
        "print(\"done step 1\")\n",
        "for i in range(78, 122):\n",
        "    url_QnA_dict_2[i-77] = requests.get(links_list[i])\n",
        "print(\"done step 2\")\n",
        "for i in range(122, 162):\n",
        "    url_QnA_dict_3[i-121] = requests.get(links_list[i])\n",
        "print(\"done step 3\")\n",
        "for i in range(162, 186):\n",
        "    url_QnA_dict_4[i-161] = requests.get(links_list[i])\n",
        "print(\"done step 4\")\n",
        "for i in range(186, len(links_list)):\n",
        "    url_QnA_dict_5[i-185] = requests.get(links_list[i])\n",
        "print(\"done step 5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMsw9rWkRXBU",
        "outputId": "75176df8-7ffa-417a-e9ec-6cb9fcad89e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77\n",
            "77\n",
            "121\n",
            "121\n",
            "161\n",
            "161\n",
            "184\n",
            "184\n",
            "207\n",
            "207\n"
          ]
        }
      ],
      "source": [
        "# Create an empty list to store the QnA\n",
        "Q_list = []\n",
        "A_list = []\n",
        "\n",
        "# parse the content using BeautifulSoup\n",
        "for i in range(1, 78):\n",
        "    soup = BeautifulSoup(url_QnA_dict_1[i].content, \"html.parser\")\n",
        "    Q_list.append(soup.find(\"section\", class_=\"single_fatwa__question text-justified\").text)\n",
        "    A_list.append(soup.find(\"div\", class_=\"content\").text)\n",
        "print(len(Q_list))\n",
        "print(len(A_list))\n",
        "\n",
        "for i in range(1, 45):\n",
        "    soup = BeautifulSoup(url_QnA_dict_2[i].content, \"html.parser\")\n",
        "    Q_list.append(soup.find(\"section\", class_=\"single_fatwa__question text-justified\").text)\n",
        "    A_list.append(soup.find(\"div\", class_=\"content\").text)\n",
        "print(len(Q_list))\n",
        "print(len(A_list))\n",
        "\n",
        "for i in range(1, 41):\n",
        "    soup = BeautifulSoup(url_QnA_dict_3[i].content, \"html.parser\")\n",
        "    Q_list.append(soup.find(\"section\", class_=\"single_fatwa__question text-justified\").text)\n",
        "    A_list.append(soup.find(\"div\", class_=\"content\").text)\n",
        "print(len(Q_list))\n",
        "print(len(A_list))\n",
        "\n",
        "for i in range(1, 24):\n",
        "    soup = BeautifulSoup(url_QnA_dict_4[i].content, \"html.parser\")\n",
        "    Q_list.append(soup.find(\"section\", class_=\"single_fatwa__question text-justified\").text)\n",
        "    A_list.append(soup.find(\"div\", class_=\"content\").text)\n",
        "print(len(Q_list))\n",
        "print(len(A_list))\n",
        "\n",
        "for i in range(1, 24):\n",
        "    soup = BeautifulSoup(url_QnA_dict_5[i].content, \"html.parser\")\n",
        "    Q_list.append(soup.find(\"section\", class_=\"single_fatwa__question text-justified\").text)\n",
        "    A_list.append(soup.find(\"div\", class_=\"content\").text)\n",
        "print(len(Q_list))\n",
        "print(len(A_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5Av84NFVRbhw"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(Q_list)):\n",
        "    Q_list[i] = (Q_list[i].replace(\"Pertanyaan\", \"\")).strip()\n",
        "    A_list[i] = (A_list[i].replace(\"Alhamdulillah.\",\"\")).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iIik45Y0Reg2",
        "outputId": "f32e1215-144a-4de1-d67b-485c7ec03023"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kalau seorang ibu membersihkah (kotoran) anakn...</td>\n",
              "      <td>Pembatal-pembatal wudu sudah dikenal. Dan tela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Berdasarkan fatwa Syekh Ibnu Utsaimin tentang ...</td>\n",
              "      <td>Jika beser kencing bersifat terus menerus dan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apakah krim yang kita oleskan di tangan atau w...</td>\n",
              "      <td>Seorang wanita yang menggunakan krim atau miny...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saya berjuang melawan rasa was-was. Secara umu...</td>\n",
              "      <td>Pertama:\\nNasehat bagi anda: Jangan hiraukan k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Anda sebutkan di website anda bahwa darah itu ...</td>\n",
              "      <td>Pertama:\\nMasalah najisnya darah termasuk perm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>Apakah ahli waris dari saudaraku yang meningga...</td>\n",
              "      <td>Kalau seseorang meninggal dunia dan mempunyai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>Bapak mertua saya meninggal dunia, meninggalka...</td>\n",
              "      <td>Jika seseorang meninggal dunia dan meninggalka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Ibuku meninggal dunia – saya memohon kepada Al...</td>\n",
              "      <td>Pertama:\\nTidak boleh bagi orang tua mengkhusu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>Nenekku –rahimahallah- berwasiat menjadikan ta...</td>\n",
              "      <td>Pertama:\\nDiperbolehkan berwasiat untuk wakaf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>Apa bagian warisan untuk paman dan bibi (dari ...</td>\n",
              "      <td>Paman (dari ayah) itu asobah (sisa warisan). K...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Questions  \\\n",
              "0    Kalau seorang ibu membersihkah (kotoran) anakn...   \n",
              "1    Berdasarkan fatwa Syekh Ibnu Utsaimin tentang ...   \n",
              "2    Apakah krim yang kita oleskan di tangan atau w...   \n",
              "3    Saya berjuang melawan rasa was-was. Secara umu...   \n",
              "4    Anda sebutkan di website anda bahwa darah itu ...   \n",
              "..                                                 ...   \n",
              "202  Apakah ahli waris dari saudaraku yang meningga...   \n",
              "203  Bapak mertua saya meninggal dunia, meninggalka...   \n",
              "204  Ibuku meninggal dunia – saya memohon kepada Al...   \n",
              "205  Nenekku –rahimahallah- berwasiat menjadikan ta...   \n",
              "206  Apa bagian warisan untuk paman dan bibi (dari ...   \n",
              "\n",
              "                                                Answer  \n",
              "0    Pembatal-pembatal wudu sudah dikenal. Dan tela...  \n",
              "1    Jika beser kencing bersifat terus menerus dan ...  \n",
              "2    Seorang wanita yang menggunakan krim atau miny...  \n",
              "3    Pertama:\\nNasehat bagi anda: Jangan hiraukan k...  \n",
              "4    Pertama:\\nMasalah najisnya darah termasuk perm...  \n",
              "..                                                 ...  \n",
              "202  Kalau seseorang meninggal dunia dan mempunyai ...  \n",
              "203  Jika seseorang meninggal dunia dan meninggalka...  \n",
              "204  Pertama:\\nTidak boleh bagi orang tua mengkhusu...  \n",
              "205  Pertama:\\nDiperbolehkan berwasiat untuk wakaf ...  \n",
              "206  Paman (dari ayah) itu asobah (sisa warisan). K...  \n",
              "\n",
              "[207 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array_2d = []\n",
        "\n",
        "for i in zip(Q_list,A_list):\n",
        "  array_2d.append(list(i))\n",
        "\n",
        "pd.DataFrame(array_2d, columns = [\"Questions\", \"Answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "gU1jtN6uRgdU",
        "outputId": "eb5f921f-48cc-4070-c095-1748bf8f72d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194\n",
            "194\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saya sudah berwudu untuk shalat, namun bayi sa...</td>\n",
              "      <td>Tidak ada seorang pun dari pada ulama yang men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apakah seorang muslim diperbolehkan mendonorka...</td>\n",
              "      <td>Kalau ada keperluan mendesak yang membutuhkan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Saya baru saja masuk Islam. Saya selalu berusa...</td>\n",
              "      <td>Pertama:\\n\\n    Kami mohon kepada Allah Ta'ala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saya punya toko emas dan perhiasan, akan tetap...</td>\n",
              "      <td>Tidak dperbolehkan menjual emas dengan emas at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Saya menderita suka keluar angin yang tidak te...</td>\n",
              "      <td>Para ulama berbeda pendapat tentang wudhu oran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>Saya ingin menanyakan permasalahan yang membua...</td>\n",
              "      <td>Kalau seseorang terkena najis pada badan atau ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>Saya mempunyai toko perhiasan, sebagian keraba...</td>\n",
              "      <td>Tidak dibolehkan menjual emas dengan uang kecu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Apa hikmahnya berwudhu bagi orang yang keluar ...</td>\n",
              "      <td>Pertama: Berwudhu bagi orang yang keluar angin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Apakah diperbolehkan meminta produk dari websi...</td>\n",
              "      <td>Kalau produk di dalamnya ada syiar untuk orang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>Bagaimanakah hukumnya menggunakan sesuatu yang...</td>\n",
              "      <td>Setiap wakaf atau pemberian yang diperuntukkan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Questions  \\\n",
              "0    Saya sudah berwudu untuk shalat, namun bayi sa...   \n",
              "1    Apakah seorang muslim diperbolehkan mendonorka...   \n",
              "2    Saya baru saja masuk Islam. Saya selalu berusa...   \n",
              "3    Saya punya toko emas dan perhiasan, akan tetap...   \n",
              "4    Saya menderita suka keluar angin yang tidak te...   \n",
              "..                                                 ...   \n",
              "189  Saya ingin menanyakan permasalahan yang membua...   \n",
              "190  Saya mempunyai toko perhiasan, sebagian keraba...   \n",
              "191  Apa hikmahnya berwudhu bagi orang yang keluar ...   \n",
              "192  Apakah diperbolehkan meminta produk dari websi...   \n",
              "193  Bagaimanakah hukumnya menggunakan sesuatu yang...   \n",
              "\n",
              "                                                Answer  \n",
              "0    Tidak ada seorang pun dari pada ulama yang men...  \n",
              "1    Kalau ada keperluan mendesak yang membutuhkan ...  \n",
              "2    Pertama:\\n\\n    Kami mohon kepada Allah Ta'ala...  \n",
              "3    Tidak dperbolehkan menjual emas dengan emas at...  \n",
              "4    Para ulama berbeda pendapat tentang wudhu oran...  \n",
              "..                                                 ...  \n",
              "189  Kalau seseorang terkena najis pada badan atau ...  \n",
              "190  Tidak dibolehkan menjual emas dengan uang kecu...  \n",
              "191  Pertama: Berwudhu bagi orang yang keluar angin...  \n",
              "192  Kalau produk di dalamnya ada syiar untuk orang...  \n",
              "193  Setiap wakaf atau pemberian yang diperuntukkan...  \n",
              "\n",
              "[194 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Kerjakan latihan 4 pada cell berikut ini\n",
        "# Kelompok O Hands on 2\n",
        "# Nama Anggota Kelompok : Calvin (003) & Zikra (007)\n",
        "\n",
        "##Jaccard Similarity\n",
        "def Jaccard_Similarity(doc1, doc2):\n",
        "\n",
        "    # List the unique words in a document\n",
        "    words_doc1 = set(doc1.lower().split())\n",
        "    words_doc2 = set(doc2.lower().split())\n",
        "\n",
        "    # Find the intersection of words list of doc1 & doc2\n",
        "    intersection = words_doc1.intersection(words_doc2)\n",
        "\n",
        "    # Find the union of words list of doc1 & doc2\n",
        "    union = words_doc1.union(words_doc2)\n",
        "\n",
        "    # Calculate Jaccard similarity score\n",
        "    # using length of intersection set divided by length of union set\n",
        "    return float(len(intersection)) / len(union)\n",
        "\n",
        "array_2d = list(set(map(tuple, array_2d)))\n",
        "print(len(array_2d))\n",
        "array_2d = list(map(list, array_2d))\n",
        "print(len(array_2d))\n",
        "for i in range(0, len(array_2d)):\n",
        "    for j in range(i+1, len(array_2d)):\n",
        "        if Jaccard_Similarity(array_2d[i][0], array_2d[j][0]) > 0.9:\n",
        "            array_2d.pop(j)\n",
        "            print(len(array_2d))\n",
        "            break\n",
        "\n",
        "pd.DataFrame(array_2d, columns = [\"Questions\", \"Answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bYQzIpPVZ3lL"
      },
      "outputs": [],
      "source": [
        "arr_corpus = np.array(array_2d)\n",
        "corpus = arr_corpus.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kjttWLBZpEt",
        "outputId": "8ada5761-a1ce-4def-e6c8-4c1975693352"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac1f32ee04934c52aaa86566c9f07e77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\M-SI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\M-SI\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e630d9db0c4b403dbde3bfc4672f6f82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c63c46496a84c4799c8e7ca90b98fca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "572068fb7f5440cdbebab9b172c75db2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9be0d42188034adcb350d9f60fbfce21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80e0dfa6abc14276966be8651d78d33b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41448be239aa4d65ae147be244a7e2e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2cc5dd5db354c2896a3a33f0227b54b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5606dc98c4c74d9db797e2d72eb36f5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ae40185120c4f02bfd06fb612b76ab2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff891f47dae04e77b08a7a9db3db1c94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vkfnF2ejYRKM"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"saya wudhu memakai kaos kaki\",\n",
        "    \"saya meminjamkan dana dari bank\",\n",
        "    \"rekening aktif digunakan dalam transaksi\",\n",
        "    \"membeli barang dagangangan secara online\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE9xc1labe0i",
        "outputId": "4cea126a-673f-4b0f-f0e0-6d3370d4ddd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: saya wudhu memakai kaos kaki\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Saya berwudhu, lalu saya memakai kaos kaki, kemudian saya shalat Isya, kemudian saya bangun tidur untuk shalat Shubuh, lalu saya berwudhu dengan mengusap kaos kaki (sebagai pengganti membasuh kaki). Kemudian saya shalat Shubuh. Wudhu saya tidak batal, kemudian saya mengganti kaos kaki saya dengan kaos kaki lain. Lalu datang waktu shalat Zuhur, kemudian saya berwudhu dan mengusap kaos kaki kedua yang saya pakai sesaat setelah saya melepas yang pertama sedangkan saya dalam keadaan suci. Apakah shalat Zuhur saya sah karena wudhunya sah, atau batal karena wudhunya batal? (Score: 0.6296)\n",
            "Saya ingin penjelasan tentang sebuah masalah. Yang saya ketahui bahwa keputihan membatalkan wudhu. Saya mengalami was-was, sehingga saya harus berwudhu setiap shalat. Apakah keluarnya sedikit cairan membatalkan wudhu? Bagaimana saya membedakannya dengan keringat. Karena sulit bagi saya untuk membedakannya? (Score: 0.6276)\n",
            "Saya mengalami luka pada hidung, jika saya berwudhu dan ingin menghirup air ke hidung lalu mengeluarkannya, darah keluar dari hidung. Apakah saya harus mengulangi wudhu, meskipun hal itu menyulitkan saya. (Score: 0.6006)\n",
            "Apakah muntah membatalkan wudhu? (Score: 0.5977)\n",
            "ku tentang shodakah jariyah, apakah kalau orang tuaku rahimahullah dan yang meninggal dari kalangan umat islam, membayar zakat mal kepada sebagian orang fakir, dan saya lebih mengetahui (kondisi orang fakir). Apakah diperbolehkna saya memberinya dengan dana yang sama dengan niatan shodakah jariyah dimana pahalanya insyaallah sampai kepadanya. Dan dananya dari zakat malku juga. (Score: 0.5935)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: saya meminjamkan dana dari bank\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Saya tahu bahwa bungn bank itu haram dan harus dikeluarkan seperti shodaqah. Oleh karena itu, kalau disana ada bunga bank di rekeningku, apakah harus saya tarik bunga ini dari rekening bank atau saya diperbolehkan mengeluarkan nilai yang sama dari uang cash yang ada pada diriku? (Score: 0.7655)\n",
            "Apakah dibolehkan saya menyimpan uang di bank hanya untuk transasksi saja. Saya tidak mau menerima bunga apapun terhadap uang yang saya simpan. Akan tetapi tentunya bunganya akan diambil oleh bank untuk mereka sendiri? (Score: 0.7642)\n",
            "Sebuah bank setiap tahunnya melakukan undian, para pemenangnya mendapatkan hadiah berupa uang untuk ibadah umroh. Apakah boleh menunaikan ibadah umroh dari hasil undian dari bank tersebut? (Score: 0.7507)\n",
            "Saya mempunyai dana di bank (rekening aktif), terkadang bank mengirimkan sebagian hadiah kepada diriku seperti minyak wangi atau bukhur (kayu garu yang wangi). Pihak bank juga melakukan seperti ini kepada sebagian pelanggan yang mempunyai dana banyak di rekeningnya. Apa hukum hadiah ini? (Score: 0.7428)\n",
            "Ada fenomena baru dari berbarapa bank yang memberikan pinjaman kepada mahasiswa dan wisudawan dengan jaminan kampus atau pekerjaan. Bantuan berupa 60% cash dan 40% dalam bentuk belanjaan sedangkan bunga diambil dari pinjaman cash dari sejak peminjaman sedangkan bunga dari belanjaan dimulai setelah 45 hari pembelanjaan. Saya ingin mengetahui apakah perkara ini termasuk riba atau bukan? Jika riba sedangkan transaksi sudah terjadi, apa yang dilakukan? (Score: 0.7427)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: rekening aktif digunakan dalam transaksi\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Apa hikmahnya berwudhu karena makan daging onta? (Score: 0.5513)\n",
            "Seseorang mewakafkan hartanya untuk fakir miskin. Apakah harta tersebut wajib dizakatkan? (Score: 0.5454)\n",
            "Kakek saya telah meninggal dunia –rahimahullah rahmatan wasi’ah-, lalu ada lembaga asuransi dan pensiunan memberikan santunan kematian, di negara kami dinamakan: “Al Khorijah”, pertanyaan saya adalah:\n",
            "Apakah dana santunan tersebut menjadi bagian dari harta warisan yang diwariskan kepada anak-anaknya ? atau semua santunan itu diberikan kepada istrinya. (Score: 0.5400)\n",
            "Apakah diperbolehkan salah seorang penerima wakaf tertahan diberikan kepada penerima (wakaf) lainnya? (Score: 0.5377)\n",
            "Tidak mengapa meletakkan harta wakaf di saham perusahaan yang tidak beroperasi dengan system riba jika perusahaan tersebut terpercaya, lalu keuntungannya digunakan untuk berkurban.\n",
            "Hanya Allah pemberi taufiq. (Score: 0.5376)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: membeli barang dagangangan secara online\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Bagaimanakah hukum jual beli pada waktu shalat jum’at melalui internet karena barang yang saya jual adalah barang digital yang akan langsung sampai kepada pelanggan setelah membayar pada akun pribadi saya ? (Score: 0.6270)\n",
            "Toko emas membeli emas kepada distributor emas lewat telpon, kemudian mereka telah sepakat harganya, sementara barangnya sudah diperlihatkan kepada pembeli, kemudian dia mentranfer dana lewat bank. Pedagang (penjual) mengirimkan emas kepadanya. Apakah hal ini dibolehkan? (Score: 0.6043)\n",
            "Karpet masjid dan AC lama masjid, apakah boleh dijual dan hasilnya dijadikan pelengkap untuk membeli yang baru ? (Score: 0.5815)\n",
            "Seseoarng menjamin pinjaman dengan sejumlah untuk membeli rumah di samping masjid agar dapat digunakan sebagai sisi masjid. Kemudian setelah itu orang ini menaruh rumah ini atas namanya sebagai pengganti atas nama masjid. Apa yang perlu dilakukan sekarang? Hak rumah apakah untuk masjid atau untuk orang itu? (Score: 0.5716)\n",
            "Mohon penjelasan tentang apakah keluarnya darah dapat membatalkan shalat? (Score: 0.5617)\n"
          ]
        }
      ],
      "source": [
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "top_k = min(5, len(corpus))\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
        "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Y8AVW9Zlbfbd"
      },
      "outputs": [
        {
          "ename": "ZeroDivisionError",
          "evalue": "float division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[44], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f1_score\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[1;32m---> 20\u001b[0m     precision, recall, f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery:\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n",
            "Cell \u001b[1;32mIn[44], line 15\u001b[0m, in \u001b[0;36mevaluate_query\u001b[1;34m(query, corpus, corpus_embeddings)\u001b[0m\n\u001b[0;32m     13\u001b[0m precision \u001b[38;5;241m=\u001b[39m relevant \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     14\u001b[0m recall \u001b[38;5;241m=\u001b[39m relevant \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(corpus)\n\u001b[1;32m---> 15\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f1_score\n",
            "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Average Precision (MAP): 1.0000\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
